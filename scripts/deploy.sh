#!/bin/bash

# æ™ºèƒ½å·¥ä½œåŠ©æ‰‹éƒ¨ç½²è„šæœ¬
# Intelligent Work Assistant Deployment Script

set -euo pipefail

# ================================
# é…ç½®å˜é‡
# ================================
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
DEPLOY_DIR="/opt/intelligent-work-assistant"
BACKUP_DIR="/opt/intelligent-work-assistant/backups"
LOG_FILE="/var/log/iwa-deploy.log"

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# ================================
# å·¥å…·å‡½æ•°
# ================================
log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}" | tee -a "$LOG_FILE"
}

warn() {
    echo -e "${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}" | tee -a "$LOG_FILE"
}

error() {
    echo -e "${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}" | tee -a "$LOG_FILE"
    exit 1
}

info() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')] INFO: $1${NC}" | tee -a "$LOG_FILE"
}

# æ£€æŸ¥æ˜¯å¦ä¸º root ç”¨æˆ·
check_root() {
    if [[ $EUID -ne 0 ]]; then
        error "æ­¤è„šæœ¬éœ€è¦ root æƒé™è¿è¡Œ"
    fi
}

# æ£€æŸ¥ç³»ç»Ÿè¦æ±‚
check_requirements() {
    log "æ£€æŸ¥ç³»ç»Ÿè¦æ±‚..."
    
    # æ£€æŸ¥æ“ä½œç³»ç»Ÿ
    if [[ ! -f /etc/os-release ]]; then
        error "æ— æ³•è¯†åˆ«æ“ä½œç³»ç»Ÿ"
    fi
    
    source /etc/os-release
    log "æ“ä½œç³»ç»Ÿ: $NAME $VERSION"
    
    # æ£€æŸ¥å¿…è¦å‘½ä»¤
    local commands=("docker" "docker-compose" "curl" "git" "openssl")
    for cmd in "${commands[@]}"; do
        if ! command -v "$cmd" &> /dev/null; then
            error "ç¼ºå°‘å¿…è¦å‘½ä»¤: $cmd"
        fi
    done
    
    # æ£€æŸ¥ Docker æœåŠ¡
    if ! systemctl is-active --quiet docker; then
        error "Docker æœåŠ¡æœªè¿è¡Œ"
    fi
    
    # æ£€æŸ¥ç£ç›˜ç©ºé—´ (è‡³å°‘éœ€è¦ 10GB)
    local available_space=$(df / | tail -1 | awk '{print $4}')
    local required_space=$((10 * 1024 * 1024)) # 10GB in KB
    
    if [[ $available_space -lt $required_space ]]; then
        error "ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œè‡³å°‘éœ€è¦ 10GB å¯ç”¨ç©ºé—´"
    fi
    
    log "ç³»ç»Ÿè¦æ±‚æ£€æŸ¥é€šè¿‡"
}

# åˆ›å»ºéƒ¨ç½²ç›®å½•ç»“æ„
create_directories() {
    log "åˆ›å»ºéƒ¨ç½²ç›®å½•ç»“æ„..."
    
    local directories=(
        "$DEPLOY_DIR"
        "$DEPLOY_DIR/data"
        "$DEPLOY_DIR/data/mongodb"
        "$DEPLOY_DIR/data/redis"
        "$DEPLOY_DIR/data/prometheus"
        "$DEPLOY_DIR/data/grafana"
        "$DEPLOY_DIR/data/elasticsearch"
        "$DEPLOY_DIR/config"
        "$DEPLOY_DIR/config/mongodb"
        "$DEPLOY_DIR/config/nginx"
        "$DEPLOY_DIR/logs"
        "$DEPLOY_DIR/logs/nginx"
        "$DEPLOY_DIR/logs/security"
        "$DEPLOY_DIR/logs/audit"
        "$DEPLOY_DIR/uploads"
        "$DEPLOY_DIR/uploads/temp"
        "$DEPLOY_DIR/uploads/documents"
        "$DEPLOY_DIR/uploads/audio"
        "$DEPLOY_DIR/uploads/images"
        "$DEPLOY_DIR/backups"
        "$DEPLOY_DIR/backups/mongodb"
        "$DEPLOY_DIR/backups/files"
        "$DEPLOY_DIR/quarantine"
        "$DEPLOY_DIR/ssl"
        "$DEPLOY_DIR/scripts"
        "$DEPLOY_DIR/monitoring"
        "$DEPLOY_DIR/logging"
    )
    
    for dir in "${directories[@]}"; do
        mkdir -p "$dir"
        log "åˆ›å»ºç›®å½•: $dir"
    done
    
    # è®¾ç½®ç›®å½•æƒé™
    chown -R 1001:1001 "$DEPLOY_DIR/uploads"
    chown -R 1001:1001 "$DEPLOY_DIR/logs"
    chmod -R 755 "$DEPLOY_DIR/uploads"
    chmod -R 750 "$DEPLOY_DIR/logs"
    chmod -R 700 "$DEPLOY_DIR/quarantine"
    chmod -R 700 "$DEPLOY_DIR/backups"
    
    log "ç›®å½•ç»“æ„åˆ›å»ºå®Œæˆ"
}

# å¤åˆ¶é¡¹ç›®æ–‡ä»¶
copy_project_files() {
    log "å¤åˆ¶é¡¹ç›®æ–‡ä»¶..."
    
    # å¤åˆ¶ Docker é…ç½®
    cp "$PROJECT_ROOT/docker-compose.prod.yml" "$DEPLOY_DIR/"
    cp "$PROJECT_ROOT/Dockerfile.prod" "$DEPLOY_DIR/"
    
    # å¤åˆ¶é…ç½®æ–‡ä»¶
    if [[ -f "$PROJECT_ROOT/.env.production" ]]; then
        cp "$PROJECT_ROOT/.env.production" "$DEPLOY_DIR/"
    else
        warn ".env.production æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ‰‹åŠ¨åˆ›å»º"
    fi
    
    # å¤åˆ¶è„šæœ¬
    cp -r "$PROJECT_ROOT/scripts"/* "$DEPLOY_DIR/scripts/" 2>/dev/null || true
    
    # å¤åˆ¶ç›‘æ§é…ç½®
    cp -r "$PROJECT_ROOT/monitoring"/* "$DEPLOY_DIR/monitoring/" 2>/dev/null || true
    
    # å¤åˆ¶æ—¥å¿—é…ç½®
    cp -r "$PROJECT_ROOT/logging"/* "$DEPLOY_DIR/logging/" 2>/dev/null || true
    
    log "é¡¹ç›®æ–‡ä»¶å¤åˆ¶å®Œæˆ"
}

# ç”Ÿæˆ SSL è¯ä¹¦ (è‡ªç­¾åè¯ä¹¦ç”¨äºæµ‹è¯•)
generate_ssl_certificates() {
    log "ç”Ÿæˆ SSL è¯ä¹¦..."
    
    local ssl_dir="$DEPLOY_DIR/ssl"
    local domain="intelligent-assistant.local"
    
    if [[ ! -f "$ssl_dir/server.crt" ]]; then
        # åˆ›å»ºç§é’¥
        openssl genrsa -out "$ssl_dir/server.key" 2048
        
        # åˆ›å»ºè¯ä¹¦ç­¾åè¯·æ±‚
        openssl req -new -key "$ssl_dir/server.key" -out "$ssl_dir/server.csr" -subj "/C=CN/ST=Beijing/L=Beijing/O=IWA/CN=$domain"
        
        # åˆ›å»ºè‡ªç­¾åè¯ä¹¦
        openssl x509 -req -days 365 -in "$ssl_dir/server.csr" -signkey "$ssl_dir/server.key" -out "$ssl_dir/server.crt"
        
        # è®¾ç½®æƒé™
        chmod 600 "$ssl_dir/server.key"
        chmod 644 "$ssl_dir/server.crt"
        
        log "SSL è¯ä¹¦ç”Ÿæˆå®Œæˆ"
    else
        log "SSL è¯ä¹¦å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆ"
    fi
}

# é…ç½® Nginx
configure_nginx() {
    log "é…ç½® Nginx..."
    
    local nginx_conf="$DEPLOY_DIR/config/nginx/default.conf"
    
    cat > "$nginx_conf" << 'EOF'
# Nginx configuration for Intelligent Work Assistant
upstream app_backend {
    server app:5000;
    keepalive 32;
}

# HTTP to HTTPS redirect
server {
    listen 80;
    server_name _;
    return 301 https://$server_name$request_uri;
}

# Main HTTPS server
server {
    listen 443 ssl http2;
    server_name _;
    
    # SSL Configuration
    ssl_certificate /etc/ssl/certs/server.crt;
    ssl_certificate_key /etc/ssl/certs/server.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;
    
    # Security Headers
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload";
    add_header Referrer-Policy "strict-origin-when-cross-origin";
    
    # Rate limiting
    limit_req zone=general burst=10 nodelay;
    
    # Client settings
    client_max_body_size 20M;
    client_body_timeout 60s;
    client_header_timeout 60s;
    
    # Proxy settings
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_http_version 1.1;
    proxy_set_header Connection "";
    
    # Main application
    location / {
        proxy_pass http://app_backend;
        proxy_read_timeout 300s;
        proxy_connect_timeout 75s;
    }
    
    # API endpoints with specific rate limiting
    location /api/auth/ {
        limit_req zone=auth burst=5 nodelay;
        proxy_pass http://app_backend;
    }
    
    location /api/upload/ {
        limit_req zone=upload burst=3 nodelay;
        client_max_body_size 50M;
        proxy_pass http://app_backend;
        proxy_read_timeout 600s;
    }
    
    # Static files caching
    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
        expires 1y;
        add_header Cache-Control "public, immutable";
        proxy_pass http://app_backend;
    }
    
    # Health check
    location /health {
        access_log off;
        proxy_pass http://app_backend;
    }
    
    # Block access to sensitive files
    location ~ /\.(env|git|svn|htaccess|htpasswd) {
        deny all;
        return 404;
    }
}

# Rate limiting zones (add to nginx.conf)
# limit_req_zone $binary_remote_addr zone=general:10m rate=100r/m;
# limit_req_zone $binary_remote_addr zone=auth:10m rate=20r/m;
# limit_req_zone $binary_remote_addr zone=upload:10m rate=10r/m;
EOF
    
    log "Nginx é…ç½®å®Œæˆ"
}

# é…ç½®æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
configure_database() {
    log "é…ç½®æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬..."
    
    local mongo_init="$DEPLOY_DIR/scripts/mongo-init.js"
    
    cat > "$mongo_init" << 'EOF'
// MongoDB initialization script
db = db.getSiblingDB('intelligent_work_assistant');

// Create application user
db.createUser({
  user: 'iwa_user',
  pwd: process.env.MONGODB_USER_PASSWORD,
  roles: [
    {
      role: 'readWrite',
      db: 'intelligent_work_assistant'
    }
  ]
});

// Create indexes for better performance
db.users.createIndex({ email: 1 }, { unique: true });
db.users.createIndex({ wechatOpenId: 1 });
db.tasks.createIndex({ userId: 1, createdAt: -1 });
db.meetings.createIndex({ userId: 1, scheduledAt: 1 });
db.documents.createIndex({ userId: 1, createdAt: -1 });
db.notifications.createIndex({ userId: 1, read: 1, createdAt: -1 });
db.wechatBindings.createIndex({ openid: 1 }, { unique: true });
db.wechatBindings.createIndex({ bindCode: 1 });

print('Database initialization completed');
EOF
    
    # ç”Ÿæˆ MongoDB keyfile
    openssl rand -base64 741 > "$DEPLOY_DIR/config/mongodb/mongodb-keyfile"
    chmod 600 "$DEPLOY_DIR/config/mongodb/mongodb-keyfile"
    chown 999:999 "$DEPLOY_DIR/config/mongodb/mongodb-keyfile"
    
    log "æ•°æ®åº“é…ç½®å®Œæˆ"
}

# åˆ›å»ºå¤‡ä»½è„šæœ¬
create_backup_script() {
    log "åˆ›å»ºå¤‡ä»½è„šæœ¬..."
    
    local backup_script="$DEPLOY_DIR/scripts/backup.sh"
    
    cat > "$backup_script" << 'EOF'
#!/bin/bash

# Intelligent Work Assistant Backup Script
# æ™ºèƒ½å·¥ä½œåŠ©æ‰‹å¤‡ä»½è„šæœ¬

set -euo pipefail

BACKUP_DIR="/opt/intelligent-work-assistant/backups"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
MONGODB_CONTAINER="iwa-mongodb"
REDIS_CONTAINER="iwa-redis"

# Create backup directories
mkdir -p "$BACKUP_DIR/mongodb/$TIMESTAMP"
mkdir -p "$BACKUP_DIR/redis/$TIMESTAMP"
mkdir -p "$BACKUP_DIR/files/$TIMESTAMP"

echo "Starting backup process..."

# Backup MongoDB
echo "Backing up MongoDB..."
docker exec $MONGODB_CONTAINER mongodump --authenticationDatabase admin -u root -p "$MONGODB_ROOT_PASSWORD" --out "/backups/mongodb/$TIMESTAMP"

# Backup Redis
echo "Backing up Redis..."
docker exec $REDIS_CONTAINER redis-cli -a "$REDIS_PASSWORD" --rdb "/data/dump_$TIMESTAMP.rdb"
docker cp "$REDIS_CONTAINER:/data/dump_$TIMESTAMP.rdb" "$BACKUP_DIR/redis/$TIMESTAMP/"

# Backup application files
echo "Backing up application files..."
cp -r /opt/intelligent-work-assistant/uploads "$BACKUP_DIR/files/$TIMESTAMP/"
cp /opt/intelligent-work-assistant/.env.production "$BACKUP_DIR/files/$TIMESTAMP/"

# Compress backups
echo "Compressing backups..."
cd "$BACKUP_DIR"
tar -czf "iwa_backup_$TIMESTAMP.tar.gz" "mongodb/$TIMESTAMP" "redis/$TIMESTAMP" "files/$TIMESTAMP"

# Clean up individual directories
rm -rf "mongodb/$TIMESTAMP" "redis/$TIMESTAMP" "files/$TIMESTAMP"

# Remove backups older than 30 days
find "$BACKUP_DIR" -name "iwa_backup_*.tar.gz" -mtime +30 -delete

echo "Backup completed: iwa_backup_$TIMESTAMP.tar.gz"
EOF
    
    chmod +x "$backup_script"
    
    # åˆ›å»º crontab æ¡ç›® (æ¯å¤©å‡Œæ™¨ 2 ç‚¹å¤‡ä»½)
    (crontab -l 2>/dev/null; echo "0 2 * * * $backup_script >> /var/log/iwa-backup.log 2>&1") | crontab -
    
    log "å¤‡ä»½è„šæœ¬åˆ›å»ºå®Œæˆ"
}

# é…ç½®ç›‘æ§
setup_monitoring() {
    log "é…ç½®ç›‘æ§ç³»ç»Ÿ..."
    
    # Prometheus é…ç½®
    cat > "$DEPLOY_DIR/monitoring/prometheus.yml" << 'EOF'
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'intelligent-work-assistant'
    static_configs:
      - targets: ['app:5000']
    metrics_path: '/metrics'
    scrape_interval: 30s

  - job_name: 'mongodb'
    static_configs:
      - targets: ['mongodb:27017']
    scrape_interval: 30s

  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    scrape_interval: 30s

  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx:80']
    scrape_interval: 30s
EOF
    
    log "ç›‘æ§é…ç½®å®Œæˆ"
}

# å¯åŠ¨æœåŠ¡
start_services() {
    log "å¯åŠ¨æœåŠ¡..."
    
    cd "$DEPLOY_DIR"
    
    # æ‹‰å–æœ€æ–°é•œåƒ
    docker-compose -f docker-compose.prod.yml pull
    
    # å¯åŠ¨æœåŠ¡
    docker-compose -f docker-compose.prod.yml up -d
    
    # ç­‰å¾…æœåŠ¡å¯åŠ¨
    log "ç­‰å¾…æœåŠ¡å¯åŠ¨..."
    sleep 30
    
    # å¥åº·æ£€æŸ¥
    local max_attempts=10
    local attempt=1
    
    while [[ $attempt -le $max_attempts ]]; do
        if curl -f -s http://localhost:5000/health > /dev/null; then
            log "æœåŠ¡å¯åŠ¨æˆåŠŸï¼"
            break
        fi
        
        warn "ç­‰å¾…æœåŠ¡å¯åŠ¨... ($attempt/$max_attempts)"
        sleep 10
        ((attempt++))
    done
    
    if [[ $attempt -gt $max_attempts ]]; then
        error "æœåŠ¡å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"
    fi
    
    # æ˜¾ç¤ºæœåŠ¡çŠ¶æ€
    docker-compose -f docker-compose.prod.yml ps
}

# æ˜¾ç¤ºéƒ¨ç½²ä¿¡æ¯
show_deployment_info() {
    log "éƒ¨ç½²å®Œæˆï¼"
    
    echo ""
    echo "================================"
    echo "ğŸ‰ æ™ºèƒ½å·¥ä½œåŠ©æ‰‹éƒ¨ç½²ä¿¡æ¯"
    echo "================================"
    echo "ğŸ“ éƒ¨ç½²ç›®å½•: $DEPLOY_DIR"
    echo "ğŸŒ åº”ç”¨åœ°å€: https://$(hostname -f)"
    echo "ğŸ“š API æ–‡æ¡£: https://$(hostname -f)/api-docs"
    echo "ğŸ” å¥åº·æ£€æŸ¥: https://$(hostname -f)/health"
    echo ""
    echo "ğŸ”§ ç®¡ç†å‘½ä»¤:"
    echo "  å¯åŠ¨æœåŠ¡: cd $DEPLOY_DIR && docker-compose -f docker-compose.prod.yml up -d"
    echo "  åœæ­¢æœåŠ¡: cd $DEPLOY_DIR && docker-compose -f docker-compose.prod.yml down"
    echo "  æŸ¥çœ‹æ—¥å¿—: cd $DEPLOY_DIR && docker-compose -f docker-compose.prod.yml logs -f"
    echo "  æ‰§è¡Œå¤‡ä»½: $DEPLOY_DIR/scripts/backup.sh"
    echo ""
    echo "ğŸ“‹ é…ç½®æ–‡ä»¶:"
    echo "  åº”ç”¨é…ç½®: $DEPLOY_DIR/.env.production"
    echo "  Nginx é…ç½®: $DEPLOY_DIR/config/nginx/default.conf"
    echo "  ç›‘æ§é…ç½®: $DEPLOY_DIR/monitoring/prometheus.yml"
    echo ""
    echo "ğŸ“Š å¯é€‰ç›‘æ§æœåŠ¡ (éœ€è¦å¯ç”¨):"
    echo "  Prometheus: http://$(hostname -f):9090"
    echo "  Grafana: http://$(hostname -f):3001"
    echo "  Kibana: http://$(hostname -f):5601"
    echo ""
    echo "å¯ç”¨ç›‘æ§: cd $DEPLOY_DIR && docker-compose --profile monitoring -f docker-compose.prod.yml up -d"
    echo "å¯ç”¨æ—¥å¿—: cd $DEPLOY_DIR && docker-compose --profile logging -f docker-compose.prod.yml up -d"
    echo ""
}

# ================================
# ä¸»å‡½æ•°
# ================================
main() {
    log "å¼€å§‹éƒ¨ç½²æ™ºèƒ½å·¥ä½œåŠ©æ‰‹..."
    
    # é¢„æ£€æŸ¥
    check_root
    check_requirements
    
    # éƒ¨ç½²æ­¥éª¤
    create_directories
    copy_project_files
    generate_ssl_certificates
    configure_nginx
    configure_database
    create_backup_script
    setup_monitoring
    start_services
    
    # å®Œæˆéƒ¨ç½²
    show_deployment_info
    
    log "éƒ¨ç½²å®Œæˆï¼ğŸ‰"
}

# è„šæœ¬å…¥å£
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi